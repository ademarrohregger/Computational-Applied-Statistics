{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "- Donwload  ziptrain.csv and ziptest.csv datasets from  https://github.com/vahidpartovinia/ycbs255/\n",
    "\n",
    "# Digit learning challenge\n",
    "- Use the methods taught in the course, or a good combination of the methods taught in the course to predict all 10 digits of the zipcode data. Only use ziptrain.csv data to build your model, and evaluate the accuracy of your model on ziptest.csv \n",
    "\n",
    "- Your codes must be reproducible. We may run your codes on ziptrain.csv data on our own machine. \n",
    "\n",
    "# Submission note\n",
    "Please fill this jupyter notebook. Extract the pdf file as follows. On  Jupyter manue go to File/Print Preview, then on Browser menu go to File/Print. \n",
    "\n",
    "## Only PDF  Submissions will be graded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries/Modules/Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "import time\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ziptrain = np.loadtxt(r\"C:\\Users\\olive\\Documents\\GitHub\\Computational-Applied-Statistics\\Assignment 4\\ziptrain.csv\")\n",
    "ziptest = np.loadtxt(r\"C:\\Users\\olive\\Documents\\GitHub\\Computational-Applied-Statistics\\Assignment 4\\ziptest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = ziptrain[:, 1:], ziptest[:, 1:]\n",
    "y_train, y_test = ziptrain[:, 0], ziptest[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label_binarize(y_train, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y_test = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x277768e0470>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "plt.imshow(-X_train[0].reshape(16,16), 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Grids For Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid = namedtuple(\"Grid\", ['model', 'param_grid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 4 methods: Bagging, Random Forest, Boosting and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the grid for each method to tune for optimal performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = [\n",
    "    Grid(BaggingClassifier,\n",
    "        {'estimator__n_estimators': [200, 400, 600, 800, 1000],\n",
    "        'estimator__max_samples': [800, 1000, 1200, 1400]}),\n",
    "    Grid(RandomForestClassifier,\n",
    "        {'estimator__max_depth': [70, 80, 90, 100, None],\n",
    "         'estimator__max_features': ['auto', 'sqrt'],\n",
    "         'estimator__n_estimators': [200, 400, 600, 800, 1000]}),\n",
    "    Grid(GradientBoostingClassifier,\n",
    "         {'estimator__max_depth':[3, 4, 5, 6], \n",
    "          'estimator__n_estimators':[100,250,500,750,1000]}),\n",
    "    Grid(SVC, \n",
    "    {\"estimator__C\": [4, 8, 10, 12], \n",
    "     \"estimator__degree\":[3, 4, 5, 6]})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Gridsearch to find hyperparameters that optimize the 4 methods defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def perform_gridsearch(grid):\n",
    "\n",
    "    print(\"Starting grid {}\".format(str(grid)))\n",
    "    model = OneVsRestClassifier(grid.model())\n",
    "    gs = GridSearchCV(model, param_grid=grid.param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    res = {\"Model\" : grid.model, \"Best Parameters\" : gs.best_params_, \"Accuracy\" : gs.best_score_}\n",
    "    print(\"\\n\")\n",
    "    print(\"Results from grid:\")\n",
    "    print(res)\n",
    "    print(\"\\n\")\n",
    "    return gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid Grid(model=<class 'sklearn.ensemble.bagging.BaggingClassifier'>, param_grid={'estimator__n_estimators': [200, 400, 600, 800, 1000], 'estimator__max_samples': [800, 1000, 1200, 1400]})\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 83.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 287.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results from grid:\n",
      "{'Model': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Best Parameters': {'estimator__max_samples': 1400, 'estimator__n_estimators': 600}, 'Accuracy': 0.8244410917569607}\n",
      "\n",
      "\n",
      "Starting grid Grid(model=<class 'sklearn.ensemble.forest.RandomForestClassifier'>, param_grid={'estimator__max_depth': [70, 80, 90, 100, None], 'estimator__max_features': ['auto', 'sqrt'], 'estimator__n_estimators': [200, 400, 600, 800, 1000]})\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 76.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 105.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results from grid:\n",
      "{'Model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'Best Parameters': {'estimator__max_depth': 100, 'estimator__max_features': 'sqrt', 'estimator__n_estimators': 800}, 'Accuracy': 0.8847894664655054}\n",
      "\n",
      "\n",
      "Starting grid Grid(model=<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, param_grid={'estimator__max_depth': [3, 4, 5, 6], 'estimator__n_estimators': [100, 250, 500, 750, 1000]})\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 55.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 140.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results from grid:\n",
      "{'Model': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'Best Parameters': {'estimator__max_depth': 3, 'estimator__n_estimators': 1000}, 'Accuracy': 0.9273076395556165}\n",
      "\n",
      "\n",
      "Starting grid Grid(model=<class 'sklearn.svm.classes.SVC'>, param_grid={'estimator__C': [4, 8, 10, 12], 'estimator__degree': [3, 4, 5, 6]})\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results from grid:\n",
      "{'Model': <class 'sklearn.svm.classes.SVC'>, 'Best Parameters': {'estimator__C': 12, 'estimator__degree': 3}, 'Accuracy': 0.9587162254834728}\n",
      "\n",
      "\n",
      "All Processes Completed Successfully.\n"
     ]
    }
   ],
   "source": [
    "best_params = []\n",
    "for grid in grids:\n",
    "    best_params.append(perform_gridsearch(grid))\n",
    "print(\"All Processes Completed Successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the best parameters dictionary keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_estimator(d):\n",
    "    for i in d.keys():\n",
    "        d[re.sub('estimator__', '', i)] = d.pop(i)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(best_params)):\n",
    "    best_params[i] = remove_estimator(best_params[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define method set with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models =[\n",
    "    OneVsRestClassifier(BaggingClassifier(**best_params[0])),\n",
    "    OneVsRestClassifier(RandomForestClassifier(**best_params[1])),\n",
    "    OneVsRestClassifier(GradientBoostingClassifier(**best_params[2])),\n",
    "    OneVsRestClassifier(SVC(**best_params[3]))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit tuned algorithms and compare results for each method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30 folds so the mean score is statistically significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 30 K-Fold Evaluation for Model OneVsRestClassifier(estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1400,\n",
      "         n_estimators=600, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False),\n",
      "          n_jobs=1):\n",
      "1 / 30\n",
      "2 / 30\n",
      "3 / 30\n",
      "4 / 30\n",
      "5 / 30\n",
      "6 / 30\n",
      "7 / 30\n",
      "8 / 30\n",
      "9 / 30\n",
      "10 / 30\n",
      "11 / 30\n",
      "12 / 30\n",
      "13 / 30\n",
      "14 / 30\n",
      "15 / 30\n",
      "16 / 30\n",
      "17 / 30\n",
      "18 / 30\n",
      "19 / 30\n",
      "20 / 30\n",
      "21 / 30\n",
      "22 / 30\n",
      "23 / 30\n",
      "24 / 30\n",
      "25 / 30\n",
      "26 / 30\n",
      "27 / 30\n",
      "28 / 30\n",
      "29 / 30\n",
      "30 / 30\n",
      "Mean Accuracy: 0.8285541613258673\n",
      "Standard Deviation of Accuracy: 0.02275865050772631\n",
      "\n",
      "\n",
      "Starting 30 K-Fold Evaluation for Model OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=100, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "          n_jobs=1):\n",
      "1 / 30\n",
      "2 / 30\n",
      "3 / 30\n",
      "4 / 30\n",
      "5 / 30\n",
      "6 / 30\n",
      "7 / 30\n",
      "8 / 30\n",
      "9 / 30\n",
      "10 / 30\n",
      "11 / 30\n",
      "12 / 30\n",
      "13 / 30\n",
      "14 / 30\n",
      "15 / 30\n",
      "16 / 30\n",
      "17 / 30\n",
      "18 / 30\n",
      "19 / 30\n",
      "20 / 30\n",
      "21 / 30\n",
      "22 / 30\n",
      "23 / 30\n",
      "24 / 30\n",
      "25 / 30\n",
      "26 / 30\n",
      "27 / 30\n",
      "28 / 30\n",
      "29 / 30\n",
      "30 / 30\n",
      "Mean Accuracy: 0.8928804335604579\n",
      "Standard Deviation of Accuracy: 0.019057482673441907\n",
      "\n",
      "\n",
      "Starting 30 K-Fold Evaluation for Model OneVsRestClassifier(estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False),\n",
      "          n_jobs=1):\n",
      "1 / 30\n",
      "2 / 30\n",
      "3 / 30\n",
      "4 / 30\n",
      "5 / 30\n",
      "6 / 30\n",
      "7 / 30\n",
      "8 / 30\n",
      "9 / 30\n",
      "10 / 30\n",
      "11 / 30\n",
      "12 / 30\n",
      "13 / 30\n",
      "14 / 30\n",
      "15 / 30\n",
      "16 / 30\n",
      "17 / 30\n",
      "18 / 30\n",
      "19 / 30\n",
      "20 / 30\n",
      "21 / 30\n",
      "22 / 30\n",
      "23 / 30\n",
      "24 / 30\n",
      "25 / 30\n",
      "26 / 30\n",
      "27 / 30\n",
      "28 / 30\n",
      "29 / 30\n",
      "30 / 30\n",
      "Mean Accuracy: 0.9377330275023048\n",
      "Standard Deviation of Accuracy: 0.014857600473523842\n",
      "\n",
      "\n",
      "Starting 30 K-Fold Evaluation for Model OneVsRestClassifier(estimator=SVC(C=12, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "          n_jobs=1):\n",
      "1 / 30\n",
      "2 / 30\n",
      "3 / 30\n",
      "4 / 30\n",
      "5 / 30\n",
      "6 / 30\n",
      "7 / 30\n",
      "8 / 30\n",
      "9 / 30\n",
      "10 / 30\n",
      "11 / 30\n",
      "12 / 30\n",
      "13 / 30\n",
      "14 / 30\n",
      "15 / 30\n",
      "16 / 30\n",
      "17 / 30\n",
      "18 / 30\n",
      "19 / 30\n",
      "20 / 30\n",
      "21 / 30\n",
      "22 / 30\n",
      "23 / 30\n",
      "24 / 30\n",
      "25 / 30\n",
      "26 / 30\n",
      "27 / 30\n",
      "28 / 30\n",
      "29 / 30\n",
      "30 / 30\n",
      "Mean Accuracy: 0.9639282421462142\n",
      "Standard Deviation of Accuracy: 0.009058197082089964\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = []\n",
    "std_accuracy = []\n",
    "for model in models:\n",
    "    accuracy = []\n",
    "    kf = KFold(n_splits=30, shuffle=True)\n",
    "    print(\"Starting 30 K-Fold Evaluation for Model {}:\".format(model))\n",
    "    i=0\n",
    "    for train_i, test_i, in kf.split(X_train):\n",
    "        i+=1\n",
    "        print(i,\"/\",30)\n",
    "        alg = model\n",
    "        alg = alg.fit(X_train[train_i], y_train[train_i])\n",
    "        y_true = y_train[test_i]\n",
    "        y_pred = alg.predict(X_train[test_i])\n",
    "        accuracy.append(accuracy_score(y_true, y_pred))\n",
    "    mean_accuracy.append(np.mean(accuracy))\n",
    "    std_accuracy.append(np.std(accuracy))\n",
    "    print(\"Mean Accuracy:\", mean_accuracy[-1])\n",
    "    print(\"Standard Deviation of Accuracy:\", std_accuracy[-1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm that performed best on the validation sets is:\n",
      "\n",
      "OneVsRestClassifier(estimator=SVC(C=12, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "          n_jobs=1)\n",
      "\n",
      "As it received an accuracy score of 0.9639282421462142 with a standard deviation of 0.009058197082089964\n"
     ]
    }
   ],
   "source": [
    "print(\"The algorithm that performed best on the validation sets is:\\n\\n{}\\n\\n\".format(models[-1]) +\n",
    "\"As it received an accuracy score of {} with a standard deviation of {}\".format(mean_accuracy[-1], std_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on the Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9212755356253114\n",
      "Confusion Matrix: \n",
      "[[356   0   2   0   1   0   0   0   0   0]\n",
      " [  2 255   0   0   4   0   3   0   0   0]\n",
      " [ 15   0 178   1   1   0   0   1   2   0]\n",
      " [ 15   0   1 145   0   3   0   0   1   1]\n",
      " [  9   1   2   0 184   1   1   0   0   2]\n",
      " [ 11   0   0   2   1 145   0   0   1   0]\n",
      " [  4   1   3   0   3   1 158   0   0   0]\n",
      " [  8   0   1   1   3   0   0 133   1   0]\n",
      " [ 17   0   0   2   0   1   0   0 146   0]\n",
      " [  7   0   0   0   2   0   0   0   0 168]]\n"
     ]
    }
   ],
   "source": [
    "alg = OneVsRestClassifier(SVC(C=12, gamma='auto', kernel='rbf', degree=3))\n",
    "alg = alg.fit(X_train, y_train)\n",
    "y_true = y_test\n",
    "y_pred = alg.predict(X_test)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print(\"Confusion Matrix: \\n{}\".format(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I began this process by remembering that in Assignment 3 we had investigated PCA as a possible route for reducing dimensions to improve performance of the classifiers we used. Noticing that in the case of trying to classify all digits PCA had limited benefits – I decided to preserve time and not utilize any PCA in order to spend more time performing grid searches using high-performing classifiers. The classifiers I attempted to leverage in this assignment were 3 ensemble methods (bagging, boosting, and random forest) and a support vector classifier. From the intuition I’ve gathered from class and experience it seems that without venturing into the realm of neural networks these 4 methods tend to have the highest-performing results. Now that I had these 4 algorithms defined I need to tweak them to find the hyper-parameters that yield the best results. I started this process by performing a general gridsearch on each method to try to find the best hyperparameters to maximize accuracy. I used a 5-fold cross-validation for this process. While 5-fold cross-validation is not ideal for yielding reliable scoring for each candidate (5 is a small sample size) I had decided to start with this small number because initially I had tried a 30-fold cross validation and noticed the training time for these large grids would last weeks to yield results for each algorithm. As a compromise I decided to start with 5-fold for the general hyper-parameter gridsearch to yield the best hyperparameters for each algorithm – then enter another round of gridsearches (with smaller grids) and use 30-fold cross-validation to report the final results. The idea behind the 2x gridsearch method is the first gridsearch quickly gives you an idea of where you should be investigating ideal hyperparameters – then when you have “trimmed the fat” on the grid use 30-fold cross-validation to compare each algorithm to each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform this gridsearch I needed to binarize the labels of the output and apply a one-vs-rest classifier approach to handle all outputs of the classifier. One-vs-rest classifier means one classifier is fit per-class and for each classifier the class is fitted against all the other classes. With each of the 4 selected algorithms wrapped in this one-vs-rest classifier I was able to perform a gridsearch that optimized accuracy on the results of each class in each algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive results after evaluating on the test set were lower than expected. With an accuracy ov 96% and a low standard deviation over a 30-fold cross-validation would lead me to believe that I should anticipate a higher test-set accuracy than 92%. As a next-step to this project I would continue to fine-tune the SVC algorithm to yield better results (perhaps investigate different kernels)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
